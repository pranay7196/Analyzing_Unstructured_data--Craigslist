{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the twitter essentials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Consumer_key = 'VzNRiotxgyKZxS2JPBSfMBnvB'\n",
    "Consumer_secret = 'Q0e15B8g2ggc68UsZypQLFf93W9z4OarU0bAlfxYkh68mNk16j'\n",
    "Access_token = '46323541-HOHPe8KuCvKaHQJhVDUpnryCl0RvLWmOXN9K8H46g'\n",
    "Access_secret = 'bYUgXTYR3W1gVJCHOTbTfiLY4FF5Wibbkj36TNke2wUDf'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load required package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\samir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\samir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import tweepy \n",
    "from tweepy import OAuthHandler \n",
    "from textblob import TextBlob \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pandas_profiling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a class function to store Twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterClient(object): \n",
    "    ''' \n",
    "    Generic Twitter Class for sentiment analysis. \n",
    "    '''\n",
    "    def __init__(self): \n",
    "        ''' \n",
    "        Class constructor or initialization method. \n",
    "        '''\n",
    "        # keys and tokens from the Twitter Dev Console \n",
    "        consumer_key = Consumer_key\n",
    "        consumer_secret = Consumer_secret\n",
    "        access_token = Access_token\n",
    "        access_token_secret = Access_secret\n",
    "  \n",
    "        # attempt authentication \n",
    "        try: \n",
    "            # create OAuthHandler object \n",
    "            self.auth = OAuthHandler(consumer_key, consumer_secret) \n",
    "            # set access token and secret \n",
    "            self.auth.set_access_token(access_token, access_token_secret) \n",
    "            # create tweepy API object to fetch tweets \n",
    "            self.api = tweepy.API(self.auth) \n",
    "        except: \n",
    "            print(\"Error: Authentication Failed\") \n",
    "  \n",
    "    def clean_tweet(self, tweet): \n",
    "        ''' \n",
    "        Utility function to clean tweet text by removing links, special characters \n",
    "        using simple regex statements. \n",
    "        '''\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split()) \n",
    "  \n",
    "    def get_tweet_sentiment(self, tweet): \n",
    "        ''' \n",
    "        Utility function to classify sentiment of passed tweet \n",
    "        using textblob's sentiment method \n",
    "        '''\n",
    "        # create TextBlob object of passed tweet text \n",
    "        analysis = TextBlob(self.clean_tweet(tweet)) \n",
    "        # set sentiment \n",
    "        if analysis.sentiment.polarity > 0: \n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0: \n",
    "            return 'neutral'\n",
    "        else: \n",
    "            return 'negative'\n",
    "  \n",
    "    def get_tweets(self, query, count = 10): \n",
    "        ''' \n",
    "        Main function to fetch tweets and parse them. \n",
    "        '''\n",
    "        # empty list to store parsed tweets \n",
    "        tweets = [] \n",
    "  \n",
    "        try: \n",
    "            # call twitter api to fetch tweets \n",
    "            fetched_tweets = self.api.search(q = query, count = count) \n",
    "  \n",
    "            # parsing tweets one by one \n",
    "            for tweet in fetched_tweets: \n",
    "                # empty dictionary to store required params of a tweet \n",
    "                parsed_tweet = {} \n",
    "  \n",
    "                # saving text of tweet \n",
    "                parsed_tweet['text'] = tweet.text \n",
    "                # saving sentiment of tweet \n",
    "                parsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text) \n",
    "  \n",
    "                # appending parsed tweet to tweets list \n",
    "                if tweet.retweet_count > 0: \n",
    "                    # if tweet has retweets, ensure that it is appended only once \n",
    "                    if parsed_tweet not in tweets: \n",
    "                        tweets.append(parsed_tweet) \n",
    "                else: \n",
    "                    tweets.append(parsed_tweet) \n",
    "  \n",
    "            # return parsed tweets \n",
    "            return tweets \n",
    "  \n",
    "        except tweepy.TweepError as e: \n",
    "            # print error (if any) \n",
    "            print(\"Error : \" + str(e)) \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull Craigslist review from Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = TwitterClient() \n",
    "# calling function to get tweets \n",
    "tweets = api.get_tweets(query = 'Craigslist', count = 20000000) \n",
    "tweets_2 = api.get_tweets(query = \"craigslist's\", count = 20000000) \n",
    "\n",
    "\n",
    "# picking positive tweets from tweets \n",
    "# ptweets = tweets\n",
    "n_tweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative'] \n",
    "n_tweets_2 = [tweet for tweet in tweets_2 if tweet['sentiment'] == 'negative'] \n",
    "\n",
    "A =[]\n",
    "# for tweet in n_tweets: \n",
    "#         A.append(tweet['text'])\n",
    "        \n",
    "for tweet in n_tweets_2: \n",
    "        A.append(tweet['text'])\n",
    "        \n",
    "        text = A\n",
    "\n",
    "text = ' '.join(text)\n",
    "\n",
    "text2 = text.split()\n",
    "\n",
    "\n",
    "\n",
    "stopwords = ['Craigslist', 'Craigslist',\"Craigslist,\",'Craigslistâ€™s','craigslist','Long','listings','RT','yet','RARE',' Craigslist','Craigslist ']\n",
    "for word in list(text2):  # iterating on a copy since removing will mess things up\n",
    "    if word in stopwords:\n",
    "        text2.remove(word)\n",
    "#print(text2)\n",
    "\n",
    "import tldextract\n",
    "text2 = [tldextract.extract(s).domain for s in text2]\n",
    "\n",
    "text2 = ' '.join(text2)\n",
    "#print(len(text2))\n",
    "\n",
    "wordcloud = WordCloud().generate(text2)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of Negative reviews of the companies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull Craigslist Negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main(): \n",
    "    # creating object of TwitterClient Class \n",
    "    api = TwitterClient() \n",
    "    # calling function to get tweets \n",
    "    tweets = api.get_tweets(query = \"Craigslist's\", count = 2000000) \n",
    "\n",
    "    # picking positive tweets from tweets \n",
    "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative'] \n",
    "    \n",
    "    # percentage of positive tweets \n",
    "    print(\"Negative tweets percentage: {} %\".format(100*len(ptweets)/len(tweets))) \n",
    "  \n",
    "if __name__ == \"__main__\": \n",
    "    # calling main function \n",
    "    main() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull Ebay Negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(): \n",
    "    # creating object of TwitterClient Class \n",
    "    api = TwitterClient() \n",
    "    # calling function to get tweets \n",
    "    tweets = api.get_tweets(query = 'Ebay', count = 2000000) \n",
    "\n",
    "    # picking positive tweets from tweets \n",
    "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative'] \n",
    "    \n",
    "    # percentage of positive tweets \n",
    "    print(\"Negative tweets percentage: {} %\".format(100*len(ptweets)/len(tweets))) \n",
    "  \n",
    "if __name__ == \"__main__\": \n",
    "    # calling main function \n",
    "    main() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull Amazon Negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(): \n",
    "    # creating object of TwitterClient Class \n",
    "    api = TwitterClient() \n",
    "    # calling function to get tweets \n",
    "    tweets = api.get_tweets(query = 'Amazon', count = 2000000) \n",
    "\n",
    "    # picking positive tweets from tweets \n",
    "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative'] \n",
    "    \n",
    "    # percentage of positive tweets \n",
    "    print(\"Negative tweets percentage: {} %\".format(100*len(ptweets)/len(tweets))) \n",
    "  \n",
    "if __name__ == \"__main__\": \n",
    "    # calling main function \n",
    "    main() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull BestBuy Negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(): \n",
    "    # creating object of TwitterClient Class \n",
    "    api = TwitterClient() \n",
    "    # calling function to get tweets \n",
    "    tweets = api.get_tweets(query = 'BestBuy', count = 2000000) \n",
    "\n",
    "    # picking positive tweets from tweets \n",
    "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative'] \n",
    "    \n",
    "    # percentage of positive tweets \n",
    "    print(\"Negative tweets percentage: {} %\".format(100*len(ptweets)/len(tweets))) \n",
    "  \n",
    "if __name__ == \"__main__\": \n",
    "    # calling main function \n",
    "    main() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull Walmart Negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(): \n",
    "    # creating object of TwitterClient Class \n",
    "    api = TwitterClient() \n",
    "    # calling function to get tweets \n",
    "    tweets = api.get_tweets(query = 'Walmart', count = 2000000) \n",
    "\n",
    "    # picking positive tweets from tweets \n",
    "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative'] \n",
    "    \n",
    "    # percentage of positive tweets \n",
    "    print(\"Negative tweets percentage: {} %\".format(100*len(ptweets)/len(tweets))) \n",
    "  \n",
    "if __name__ == \"__main__\": \n",
    "    # calling main function \n",
    "    main() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution 1 - NSFW post flagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the posts scraped from the scrapy spider.\n",
    "data_sale = pd.read_csv('for_sale.csv')\n",
    "data_comm = pd.read_csv('community.csv')\n",
    "data_sale['label'] = 0\n",
    "data_comm['label'] = 0\n",
    "data_sale['source'] = 'community'\n",
    "data_comm['source'] = 'for sale'\n",
    "del data_comm['location']\n",
    "del data_sale['location']\n",
    "data2 = pd.read_csv('bestposts.csv')\n",
    "data1 = data_sale.append(data_comm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['source'] = \"best post\"\n",
    "data2['Label'] = 1\n",
    "data2['Price'] = -999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data2.reindex(columns=['date', 'title', 'title_link', 'region', 'Price', 'depth',\n",
    "        'download_timeout', 'download_slot', 'download_latency', 'Text',\n",
    "        'category', 'Label', 'source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data1.append(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy(deep = True)\n",
    "df_sol1= data.copy(deep = True)\n",
    "#df = pd.DataFrame(df.head(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning\n",
    "df_sol1['y'] = df_sol1['source'].apply(lambda x: 1 if x == \"best post\" else 0)\n",
    "\n",
    "list_keep= ['Text']\n",
    "df_sol1 = df_sol1[list_keep]\n",
    "\n",
    "# 18+ list\n",
    "list_stop_slang = ['xxx','xrated','willy','willies','whore','whoar','wanky','wanker','wank','wang','w00se','vulva','viagra','vagina','v1gra','v14gra','twunter','twunt','twatty','twathead','twat','tw4t','turd','tosser','titwank','tittywank','tittyfuck','titties','tittiefucker','tittie5','titt','tits','titfuck','tit','testicle','testical','teez','teets','t1tties','t1tt1e5','s_h_i_t','spunk','spac','son-of-a-bitch','snatch','smut','smegma','sluts','slut','skank','shitty','shittings','shitting','shitters','shitter','shitted','shits','shitings','shiting','shithead','shitfull','shitfuck','shitey','shited','shite','shitdick','shit','shi+','shemale','shagging','shaggin','shagger','shag','sh1t','sh!t','sh!+','sex','semen','scrotum','scrote','scroat','screwing','schlong','sadist','s.o.b.','s hit','rimming','rimjaw','retard','rectum','pussys','pussy','pussies','pussi','pusse','pube','pron','pricks','prick','pornos','pornography','porno','porn','poop','pissoff','pissing','pissin','pissflaps','pisses','pissers','pisser','pissed','piss','pimpis','pigfucker','phuq','phuks','phukking','phukked','phuking','phuked','phuk','phuck','phonesex','penisfucker','penis','pecker','pawn','p0rn','orgasms','orgasm','orgasims','orgasim','nutsack','numbnuts','nobjokey','nobjocky','nobhead','nob jokey','nob','niggers','nigger','niggaz','niggas','niggah','nigga','nigg4h','nigg3r','nazi','n1gger','n1gga','mutherfucker','muther','muthafuckker','muthafecker','mutha','muff','motherfucks','motherfuckka','motherfuckings','motherfucking','motherfuckin','motherfuckers','motherfucker','motherfucked','motherfuck','mother fucker','mothafucks','mothafuckings','mothafucking','mothafuckin','mothafuckers','mothafucker','mothafucked','mothafuckaz','mothafuckas','mothafucka','mothafuck','mofo','mof0','mo-fo','masturbate','masterbations','masterbation','masterbate','masterbat3','masterbat*','masterb8','master-bate','masochist','ma5terbate','ma5terb8','m45terbate','m0fo','m0f0','lusting','lust','lmfao','labia','l3itch','l3i+ch','kunilingus','kums','kumming','kummer','kum','kondums','kondum','kock','knobjokey','knobjocky','knobhead','knobend','knobed','knobead','knob','kawk','jizz','jizm','jiz','jism','jerk-off','jap','jackoff','jack-off','hotsex','horny','horniest','hore','homo','hoer','hoare','hoar','heshe','hell','hardcoresex','goddamned','goddamn','god-damned','god-dam','God','goatse','gaysex','gaylord','gangbangs','gangbanged','gangbang','f_u_c_k','fux0r','fux','fukwit','fukwhit','fuks','fukkin','fukker','fuker','fuk','fudgepacker','fudge packer','fuckwit','fuckwhit','fucks','fuckme','fuckingshitmotherfucker','fuckings','fucking','fuckin','fuckheads','fuckhead','fuckers','fucker','fucked','fucka','fuck','fooker','fook','flange','fistfucks','fistfuckings','fistfucking','fistfuckers','fistfucker','fistfucked','fistfuck','fingerfucks','fingerfucking','fingerfuckers','fingerfucker','fingerfucked','fingerfuck','fellatio','fellate','felching','fecker','feck','fcuking','fcuker','fcuk','fatass','fanyy','fannyfucker','fannyflaps','fanny','fags','fagots','fagot','faggs','faggot','faggitt','fagging','fag','f4nny','f u c k e r','f u c k','ejakulate','ejaculation','ejaculatings','ejaculating','ejaculates','ejaculated','ejaculate','dyke','duche','doosh','donkeyribber','dogging','doggin','dog-fucker','dlck','dirsa','dinks','dink','dildos','dildo','dickhead','dick','damn','d1ck','cyberfucking','cyberfuckers','cyberfucker','cyberfucked','cyberfuck','cyberfuc','cyalis','cunts','cuntlicking','cuntlicker','cuntlick','cunt','cunnilingus','cunillingus','cunilingus','cumshot','cums','cumming','cummer','cum','crap','cox','coon','coksucka','cokmuncher','cok','cocksukka','cocksuka','cocksucks','cocksucking','cocksucker','cocksucked','cocksuck','cocks','cockmuncher','cockmunch','cockhead','cockface','cock-sucker','cock','cnut','clits','clitoris','clit','cl1t','cipa','chink','cawk','carpet muncher','c0cksucker','c0ck','buttplug','buttmuch','butthole','butt','bunny fucker','bum','bugger','buceta','breasts','booooooobs','booooobs','boooobs','booobs','boobs','boob','boner','bollok','bollock','boiolas','blowjobs','blowjob','blow job','bloody','bitching','bitchin','bitches','bitchers','bitcher','bitch','biatch','bi+ch','bestiality','bestial','bellend','beastiality','beastial','bastard','ballsack','balls','ballbag','b1tch','b17ch','b00bs','b!tch','a_s_s','asswhole','assholes','asshole','assfukka','assfucker','asses','ass-fucker','ass','arse','arrse','ar5e','anus','anal','a55','5hit','5h1t','4r5e']\n",
    "pat = '|'.join([r'\\b{}\\b'.format(w) for w in list_stop_slang])\n",
    "\n",
    "df_sol1 = df_sol1.assign(new=df_sol1.replace(dict(Text={pat: ''}), regex=True))\n",
    "\n",
    "sentences = pd.Series(df_sol1.Text)\n",
    "sentences2 = pd.Series(df_sol1.new)\n",
    "\n",
    "# remove anything but characters and spaces\n",
    "sentences = sentences.str.replace('[^A-z ]','').str.replace(' +',' ').str.strip()\n",
    "\n",
    "splitwords = [ nltk.word_tokenize( str(sentence) ) for sentence in sentences ]\n",
    "\n",
    "wordcounts = [ len(words) for words in splitwords ]\n",
    "#print(wordcounts)\n",
    "sentences2 = sentences2.str.replace('[^A-z ]','').str.replace(' +',' ').str.strip()\n",
    "\n",
    "splitwords2 = [ nltk.word_tokenize( str(sentence) ) for sentence in sentences2 ]\n",
    "\n",
    "wordcounts2 = [ len(words) for words in splitwords2 ]\n",
    "#print(wordcounts2)\n",
    "\n",
    "df_sol1['count_text'] = wordcounts\n",
    "df_sol1['count_new'] = wordcounts2\n",
    "df_sol1['flag'] = df_sol1['count_text'] - df_sol1['count_new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sol1_mature = df_sol1[df_sol1['flag']!=0]\n",
    "df_sol1_clean = df_sol1[df_sol1['flag']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.0% percent of the review contains the Less than 18 content\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(wordcounts2)-1):\n",
    "    if wordcounts2[i] == wordcounts[i]:\n",
    "        count = count + 1\n",
    "    else:\n",
    "        count = count\n",
    "A = 1- count/ len(wordcounts2)\n",
    "print(str(round(A*100,0))+\"% percent of the review contains the Less than 18 content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution 2 - Viral post prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['y'] = df['source'].apply(lambda x: 1 if x == \"best post\" else 0)\n",
    "\n",
    "# Keep only description and target variable\n",
    "list_keep= ['Text','y']\n",
    "df = df[list_keep]\n",
    "df.Text= df.Text.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_majority = df[df.y==0]\n",
    "df_minority = df[df.y==1]\n",
    "\n",
    "df_majority_undersampled = df_majority.sample(df_minority.shape[0])\n",
    "\n",
    "df_final = pd.concat([df_majority_undersampled, df_minority], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating term document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_df = df_final.Text.tolist()\n",
    "\n",
    "list_tokenize = []\n",
    "list_lematize = []\n",
    "list_stop_remove = []\n",
    "\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "for i in list_df:\n",
    "    #TOKENIZE\n",
    "    token_d1 = nltk.word_tokenize(i.lower())\n",
    "    list_tokenize.append(token_d1)\n",
    "    \n",
    "    #LEMMATIZE\n",
    "    token_d2 = token_d1    \n",
    "    lemmatized_token_d2 = [lemmatizer.lemmatize(token) for token in token_d2 if token.isalpha()]\n",
    "    list_lematize.append(lemmatized_token_d2)\n",
    "    \n",
    "    #STOP WORDS REMOVAL\n",
    "    stop_words_removed = [token for token in token_d2 if not token in stopwords.words('english') if token.isalpha()]\n",
    "    list_stop_remove.append(stop_words_removed) \n",
    "\n",
    "\n",
    "def func_def(doc):\n",
    "    return doc\n",
    "\n",
    "tf_define = TfidfVectorizer(analyzer='word', tokenizer=func_def, preprocessor=func_def,token_pattern=None,\n",
    "    ngram_range=(1, 2), \n",
    "    min_df=5)  \n",
    "\n",
    "tf_define.fit(list_stop_remove)\n",
    "v = tf_define.transform(list_stop_remove)\n",
    "terms = tf_define.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert sparse matrix to dataframe\n",
    "Q = pd.DataFrame(v.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = []\n",
    "for k in tf_define.vocabulary_:\n",
    "    cols.append(k)\n",
    "rows = pd.DataFrame(Q)\n",
    "rows.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows.shape, df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_number_of_non_zeros = df_final.shape[0]*0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col = []\n",
    "for name, values in rows.iteritems():\n",
    "    if (len(rows[name].nonzero()[0])<=min_number_of_non_zeros):\n",
    "        col.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_X = rows.drop(col,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_dataset = pd.concat([df_final.y, df_X], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.shape, df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# final_dataset.to_csv(\"AUD_undersampled_final_dataset.csv\",index=False)\n",
    "# df_final.to_csv(\"AUD_undersampled_raw.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# final_dataset = pd.read_csv(\"AUD_undersampled_final_dataset.csv\")\n",
    "# df_X = final_dataset.drop('y',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, final_dataset['y'], test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "\"\"\"Building machine learning models: \n",
    "We will try 10 different classifiers to find the best classifier after tunning model's hyperparameters that will best generalize the unseen(test) data.\"\"\"\n",
    "\n",
    "'''Now initialize all the classifiers object.'''\n",
    "'''#1.Logistic Regression'''\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "\n",
    "'''#2.Support Vector Machines'''\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(gamma = 'auto')\n",
    "\n",
    "'''#3.Random Forest Classifier'''\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state = seed, n_estimators = 100)\n",
    "\n",
    "'''#4.KNN'''\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "'''#5.Gaussian Naive Bayes'''\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "\n",
    "'''#6.Decision Tree Classifier'''\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(random_state = seed)\n",
    "\n",
    "'''#7.Gradient Boosting Classifier'''\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(random_state = seed)\n",
    "\n",
    "'''#8.Adaboost Classifier'''\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abc = AdaBoostClassifier(random_state = seed)\n",
    "\n",
    "'''#9.ExtraTrees Classifier'''\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "etc = ExtraTreesClassifier(random_state = seed)\n",
    "\n",
    "'''#10.MLP Classifier'''\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "dl = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(10), random_state=seed, max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_accuracy(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    train_accuracy = model.score(X_train, y_train)\n",
    "    train_accuracy = np.round(train_accuracy*100, 2)\n",
    "    return train_accuracy\n",
    "\n",
    "\n",
    "'''Models with best training accuracy:'''\n",
    "train_accuracy = pd.DataFrame({'Train_accuracy(%)':[train_accuracy(lr), \n",
    "                                                    train_accuracy(svc), \n",
    "                                                    train_accuracy(rf), \n",
    "                                                    train_accuracy(knn), \n",
    "                                                    train_accuracy(gnb), \n",
    "                                                    train_accuracy(dt), \n",
    "                                                    train_accuracy(gbc), \n",
    "                                                    train_accuracy(abc), \n",
    "                                                    train_accuracy(etc),\n",
    "                                                    train_accuracy(dl)\n",
    "                                                   ]})\n",
    "train_accuracy.index = ['LR', 'SVC', 'RF', 'KNN', 'GNB', 'DT', 'GBC', 'ABC', 'ETC','DL']\n",
    "sorted_train_accuracy = train_accuracy.sort_values(by = 'Train_accuracy(%)', ascending = False)\n",
    "print('**Training Accuracy of the Classifiers:**')\n",
    "print(sorted_train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Create a function that returns mean cross validation score for different models.'''\n",
    "def x_val_score(model):\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    x_val_score = cross_val_score(model, X_train, y_train, cv = 10, scoring = 'accuracy').mean()\n",
    "    x_val_score = np.round(x_val_score*100, 2)\n",
    "    return x_val_score\n",
    "\n",
    "\"\"\"Let's perform k-fold (k=10) cross validation to find the classifier with the best cross validation accuracy.\"\"\"\n",
    "x_val_score = pd.DataFrame({'X_val_score(%)':[x_val_score(lr), \n",
    "                                              x_val_score(svc), \n",
    "                                              x_val_score(rf), \n",
    "                                              x_val_score(knn), \n",
    "                                              x_val_score(gnb), \n",
    "                                              x_val_score(dt), \n",
    "                                              x_val_score(gbc), \n",
    "                                              x_val_score(abc), \n",
    "                                              x_val_score(etc),\n",
    "                                              x_val_score(dl)\n",
    "                                             ]})\n",
    "x_val_score.index = ['LR', 'SVC', 'RF', 'KNN', 'GNB', 'DT', 'GBC', 'ABC', 'ETC', 'DL']\n",
    "sorted_x_val_score = x_val_score.sort_values(by = 'X_val_score(%)', ascending = False) \n",
    "print('**Models 10-fold Cross Validation Score:**')\n",
    "print(sorted_x_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Make prediction using all the trained models.'''\n",
    "model_prediction = pd.DataFrame({'RF':rf.predict(X_test), 'GBC':gbc.predict(X_test), 'ABC':abc.predict(X_test),\n",
    "                                 'ETC':etc.predict(X_test), 'DT':dt.predict(X_test), 'SVC':svc.predict(X_test), \n",
    "                                 'KNN':knn.predict(X_test), 'LR':lr.predict(X_test), 'DL':dl.predict(X_test)})\n",
    "\n",
    "\"\"\"Let's see how each model classifies a prticular class.\"\"\"\n",
    "print('**All the Models Prediction:**')\n",
    "print(model_prediction.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''All the Models AUC score on test before optimization.'''\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print('**All the Models AUC score on test:**')\n",
    "for k,v in model_prediction.items():\n",
    "    print(k,\"\\t\",roc_auc_score(y_test,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Define all the models' hyperparameters one by one first::\"\"\"\n",
    "\n",
    "'''Define hyperparameters the logistic regression will be tuned with. For LR, the following hyperparameters are usually tunned.'''\n",
    "lr_params = {'penalty':['l1', 'l2'],\n",
    "             'C': np.logspace(0, 4, 10)}\n",
    "\n",
    "'''For GBC, the following hyperparameters are usually tunned.'''\n",
    "gbc_params = {'learning_rate': [0.01, 0.02, 0.05, 0.01],\n",
    "              'max_depth': [4, 6, 8],\n",
    "              'max_features': [1.0, 0.3, 0.1], \n",
    "              'min_samples_split': [ 2, 3, 4],\n",
    "              'random_state':[seed]}\n",
    "\n",
    "'''For SVC, the following hyperparameters are usually tunned.'''\n",
    "svc_params = {'C': [6, 7, 8, 9, 10, 11, 12], \n",
    "              'kernel': ['linear','rbf'],\n",
    "              'gamma': [0.5, 0.2, 0.1, 0.001, 0.0001]}\n",
    "\n",
    "'''For DT, the following hyperparameters are usually tunned.'''\n",
    "dt_params = {'max_features': ['auto', 'sqrt', 'log2'],\n",
    "             'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], \n",
    "             'min_samples_leaf':[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
    "             'random_state':[seed]}\n",
    "\n",
    "'''For RF, the following hyperparameters are usually tunned.'''\n",
    "rf_params = {'criterion':['gini','entropy'],\n",
    "             'n_estimators':[10, 15, 20, 25, 30],\n",
    "             'min_samples_leaf':[1, 2, 3],\n",
    "             'min_samples_split':[3, 4, 5, 6, 7], \n",
    "             'max_features':['sqrt', 'auto', 'log2'],\n",
    "             'random_state':[44]}\n",
    "\n",
    "'''For KNN, the following hyperparameters are usually tunned.'''\n",
    "knn_params = {'n_neighbors':[3, 4, 5, 6, 7, 8],\n",
    "              'leaf_size':[1, 2, 3, 5],\n",
    "              'weights':['uniform', 'distance'],\n",
    "              'algorithm':['auto', 'ball_tree','kd_tree','brute']}\n",
    "\n",
    "'''For ABC, the following hyperparameters are usually tunned.'''\n",
    "abc_params = {'n_estimators':[1, 5, 10, 15, 20, 25, 40, 50, 60, 80, 100, 130, 160, 200, 250, 300],\n",
    "              'learning_rate':[0.0001, 0.001, 0.01, 0.1, 0.2, 0.3,1.5],\n",
    "              'random_state':[seed]}\n",
    "\n",
    "'''For ETC, the following hyperparameters are usually tunned.'''\n",
    "etc_params = {'max_depth':[None],\n",
    "              'max_features':[1, 3, 10],\n",
    "              'min_samples_split':[2, 3, 10],\n",
    "              'min_samples_leaf':[1, 3, 10],\n",
    "              'bootstrap':[False],\n",
    "              'n_estimators':[100, 300],\n",
    "              'criterion':[\"gini\"], \n",
    "              'random_state':[seed]}\n",
    "\n",
    "'''For DL, the following hyperparameters are usually tunned.'''\n",
    "dl_params = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Create a function to tune hyperparameters of the selected models.'''\n",
    "def tune_hyperparameters(model, params):\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    global best_params, best_score\n",
    "    # Construct grid search object with 10 fold cross validation.\n",
    "    grid = GridSearchCV(model, params, verbose = 0, cv = 10, scoring = 'accuracy', n_jobs = -1)\n",
    "    # Fit using grid search.\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_params, best_score = grid.best_params_, np.round(grid.best_score_*100, 2)\n",
    "    return best_params, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# '''Tune LR hyperparameters.'''\n",
    "# tune_hyperparameters(lr, params = lr_params)\n",
    "# lr_best_params, lr_best_score = best_params, best_score\n",
    "# print('aLR Best Score:', lr_best_score)\n",
    "# print('And Best Parameters:', lr_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"\"\"Tune GBC's hyperparameters.\"\"\"\n",
    "# tune_hyperparameters(gbc, params = gbc_params)\n",
    "# gbc_best_score, gbc_best_params = best_score, best_params\n",
    "# print('GBC Best Score:', gbc_best_score)\n",
    "# print('And Best Parameters:', gbc_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"\"\"Tune SVC's hyperparameters.\"\"\"\n",
    "# tune_hyperparameters(svc, params = svc_params)\n",
    "# svc_best_score, svc_best_params = best_score, best_params\n",
    "# print('SVC Best Score:', svc_best_score)\n",
    "# print('And Best Parameters:', svc_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"\"\"Tune DT's hyperparameters.\"\"\"\n",
    "# tune_hyperparameters(dt, params = dt_params)\n",
    "# dt_best_score, dt_best_params = best_score, best_params\n",
    "# print('DT Best Score:', dt_best_score)\n",
    "# print('And Best Parameters:', dt_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# \"\"\"Tune RF's hyperparameters.\"\"\"\n",
    "# tune_hyperparameters(rf, params = rf_params)\n",
    "# rf_best_score, rf_best_params = best_score, best_params\n",
    "# print('RF Best Score:', rf_best_score)\n",
    "# print('And Best Parameters:', rf_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"\"\"Tune KNN's hyperparameters.\"\"\"\n",
    "# tune_hyperparameters(knn, params = knn_params)\n",
    "# knn_best_score, knn_best_params = best_score, best_params\n",
    "# print('KNN Best Score:', knn_best_score)\n",
    "# print('And Best Parameters:', knn_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"\"\"Tune ABC's hyperparameters.\"\"\"\n",
    "# tune_hyperparameters(abc, params = abc_params)\n",
    "# abc_best_score, abc_best_params = best_score, best_params\n",
    "# print('ABC Best Score:', abc_best_score)\n",
    "# print('And Best Parameters:', abc_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"\"\"Tune ETC's hyperparameters.\"\"\"\n",
    "# tune_hyperparameters(etc, params = etc_params)\n",
    "# etc_best_score, etc_best_params = best_score, best_params\n",
    "# print('ETC Best Score:', etc_best_score)\n",
    "# print('And Best Parameters:', etc_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"\"\"Tune DL's hyperparameters.\"\"\"\n",
    "# tune_hyperparameters(dl, params = dl_params)\n",
    "# dl_best_score, etc_best_params = best_score, best_params\n",
    "# print('ETC Best Score:', etc_best_score)\n",
    "# print('And Best Parameters:', etc_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# '''Create a dataframe of tunned scores and sort them in descending order.'''\n",
    "# tunned_scores = pd.DataFrame({'Tunned_accuracy(%)': [lr_best_score, gbc_best_score, svc_best_score, dt_best_score, rf_best_score, knn_best_score, abc_best_score, etc_best_score, dl_best_score]})\n",
    "# tunned_scores.index = ['LR', 'GBC', 'SVC', 'DT', 'RF', 'KNN', 'ABC', 'ETC', 'DL']\n",
    "# sorted_tunned_scores = tunned_scores.sort_values(by = 'Tunned_accuracy(%)', ascending = False)\n",
    "# print('**Models Accuracy after Optimization:**')\n",
    "# print(sorted_tunned_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''#4.Create a function that compares cross validation scores with tunned scores for different models by plotting them.'''\n",
    "def compare_scores(accuracy):\n",
    "    global ax1   \n",
    "    font_size = 15\n",
    "    title_size = 18\n",
    "    ax1 = accuracy.plot.bar(legend = False,  title = 'Models %s' % ''.join(list(accuracy.columns)), figsize = (18, 5), color = 'sandybrown')\n",
    "    ax1.title.set_size(fontsize = title_size)\n",
    "    # Removes square brackets and quotes from column name after to converting list.\n",
    "    pct_bar_labels()\n",
    "    plt.ylabel('% Accuracy', fontsize = font_size)\n",
    "    plt.show()\n",
    "\n",
    "'''Compare cross validation scores with tunned scores to find the best model.'''\n",
    "print('**Comparing Cross Validation Scores with Optimized Scores:**')\n",
    "print(sorted_x_val_score)\n",
    "print(sorted_tunned_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Instantiate the models with optimized hyperparameters.'''\n",
    "rf  = RandomForestClassifier(**rf_best_params)\n",
    "gbc = GradientBoostingClassifier(**gbc_best_params)\n",
    "svc = SVC(**svc_best_params)\n",
    "knn = KNeighborsClassifier(**knn_best_params)\n",
    "etc = ExtraTreesClassifier(**etc_best_params)\n",
    "lr  = LogisticRegression(**lr_best_params)\n",
    "dt  = DecisionTreeClassifier(**dt_best_params)\n",
    "abc = AdaBoostClassifier(**abc_best_params)\n",
    "dl = MLPClassifier(**dl_best_params)\n",
    "\n",
    "'''Train all the models with optimised hyperparameters.'''\n",
    "models = {'RF':rf, 'GBC':gbc, 'SVC':svc, 'KNN':knn, 'ETC':etc, 'LR':lr, 'DT':dt, 'ABC':abc, 'DL':dl}\n",
    "print('**10-fold Cross Validation after Optimization:**')\n",
    "score = []\n",
    "for x, (keys, items) in enumerate(models.items()):\n",
    "    # Train the models with optimized parameters using cross validation.\n",
    "    # No need to fit the data. cross_val_score does that for us.\n",
    "    # But we need to fit train data for prediction in the follow session.\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    items.fit(X_train, y_train)\n",
    "    scores = cross_val_score(items, X_train, y_train, cv = 10, scoring = 'accuracy')*100\n",
    "    score.append(scores.mean())\n",
    "    print('Mean Accuracy: %0.4f (+/- %0.4f) [%s]'  % (scores.mean(), scores.std(), keys))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# '''Stack up all the models above, optimized using xgboost'''\n",
    "# from mlxtend.classifier import StackingCVClassifier\n",
    "# stack_gen = StackingCVClassifier(classifiers=(DL,RF,LR,GBC),\n",
    "#                                 meta_classifier=DL,\n",
    "#                                 use_features_in_secondary=True)\n",
    "# stack_gen.fit(np.array(X_train), np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# list_val = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "# acc_save = []\n",
    "\n",
    "# for i in list_val:\n",
    "#     from sklearn.neural_network import MLPClassifier\n",
    "#     DLmodel = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(4,i), random_state=1)\n",
    "#     # training\n",
    "#     DLmodel.fit(X_train, y_train)\n",
    "#     y_pred_DL= DLmodel.predict(X_test)\n",
    "#     # evaluation\n",
    "#     acc_DL = accuracy_score(y_test, y_pred_DL)\n",
    "#     acc_save.append(acc_DL)\n",
    "#     print(\"Number of nuerons in 2nd layer: {}\".format(i),\"DL model Accuracy: {:.2f}%\".format(acc_DL*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Make prediction using all the trained models.'''\n",
    "model_prediction = pd.DataFrame({'RF':rf.predict(X_test), 'GBC':gbc.predict(X_test), 'ABC':abc.predict(X_test),\n",
    "                                 'ETC':etc.predict(X_test), 'DT':dt.predict(X_test), 'SVC':svc.predict(X_test), \n",
    "                                 'KNN':knn.predict(X_test), 'LR':lr.predict(X_test), 'DL':DLmodel.predict(X_test)})\n",
    "\n",
    "\"\"\"Let's see how each model classifies a prticular class.\"\"\"\n",
    "print('**All the Models Prediction:**')\n",
    "print(model_prediction.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''All the Models AUC score on test after optimization.'''\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print('**All the Models AUC score on test:**')\n",
    "for k,v in model_prediction.items():\n",
    "    print(k,\"\\t\",roc_auc_score(y_test,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "'''Create a function that plot feature importance by the selected tree based models.'''\n",
    "def feature_importance(model):\n",
    "    importance = pd.DataFrame({'Feature': X_train.columns,\n",
    "                              'Importance': np.round(model.feature_importances_,3)})\n",
    "    importance = importance.sort_values(by = 'Importance', ascending = False).set_index('Feature')\n",
    "    return importance\n",
    "\n",
    "'''Create subplots of feature impotance of rf, gbc, dt, etc, and abc.'''\n",
    "fig, axes = plt.subplots(3,2, figsize = (20,40))\n",
    "fig.suptitle('Tree Based Models Feature Importance', fontsize = 28)\n",
    "tree_models = [rf, gbc, dt, etc, abc]\n",
    "tree_names = ['RF', 'GBC', 'DT', 'ETC', 'ABC']\n",
    "\n",
    "for ax, model, name in zip(axes.flatten(), tree_models, tree_names):\n",
    "    feature_importance(model).plot.barh(ax = ax, title = name, fontsize = 16, color = 'green')\n",
    "fig.delaxes(ax = axes[2,1]) # We don't need the last subplot.\n",
    "fig.tight_layout(rect = [0, 0.03, 1, 0.97])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_lstm = df_final\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "    text = text.replace('x', '')\n",
    "#    text = re.sub(r'\\W+', '', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "    return text\n",
    "df_lstm['Text'] = df_lstm['Text'].apply(clean_text)\n",
    "df_lstm['Text'] = df_lstm['Text'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(df['Text'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(df['Text'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = pd.get_dummies(df['y']).values\n",
    "print('Shape of label tensor:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XL_train, XL_test, YL_train, YL_test = train_test_split(X,Y, test_size = 0.2, random_state = 1234)\n",
    "print(XL_train.shape,YL_train.shape)\n",
    "print(XL_test.shape,YL_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(13, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accr = model.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
